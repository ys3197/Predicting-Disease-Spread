{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjY1C_1czIOb",
        "outputId": "3bb0e8b9-ecf0-4032-b362-1051837d48cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.43.0 slicer-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgJI-l9RzYaF",
        "outputId": "1c21d730-57df-4b73-a55c-b4e3909910bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.12.1 colorlog-6.7.0 optuna-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## import packages\n",
        "%matplotlib inline\n",
        "\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import statsmodels.api as sm\n",
        "import shap\n",
        "import optuna\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor, plot_importance\n",
        "import lightgbm as lgb\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "mhYCt3PUzg0v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## load data by locations\n",
        "sj_train_features = pd.read_csv(\"sj_train_features.csv\")\n",
        "sj_train_labels = pd.read_csv(\"sj_train_labels.csv\")\n",
        "sj_validation_features = pd.read_csv(\"sj_validation_features.csv\")\n",
        "sj_validation_labels = pd.read_csv(\"sj_validation_labels.csv\")\n",
        "\n",
        "iq_train_features = pd.read_csv(\"iq_train_features.csv\")\n",
        "iq_train_labels = pd.read_csv(\"iq_train_labels.csv\")\n",
        "iq_validation_features = pd.read_csv(\"iq_validation_features.csv\")\n",
        "iq_validation_labels = pd.read_csv(\"iq_validation_labels.csv\")"
      ],
      "metadata": {
        "id": "tnuHxxwlzYgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sj_train_features.drop(columns=['weekly_median_cases', 'city'], inplace=True)\n",
        "sj_validation_features.drop(columns=['weekly_median_cases', 'city'], inplace=True)\n",
        "iq_train_features.drop(columns=['weekly_median_cases', 'city'], inplace=True)\n",
        "iq_validation_features.drop(columns=['weekly_median_cases', 'city'], inplace=True)"
      ],
      "metadata": {
        "id": "ufqRm1sqzYjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LightGBM"
      ],
      "metadata": {
        "id": "jj1Kza1q0ZsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### LightGBM time split validation integrated with Optuna\n",
        "import optuna\n",
        "\n",
        "def lgb_objective_ts_cv(trial, train_features, train_labels):\n",
        "\n",
        "  param_grid = {\n",
        "      \"num_iterations\": trial.suggest_int(\"num_iterations\", 20, 100, 10),\n",
        "      \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.2, step=0.01),\n",
        "      \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 72, step=1),\n",
        "      \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
        "      \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.01, 0.1, step=0.01),\n",
        "      \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 100, step=5),\n",
        "      \"bagging_fraction\": trial.suggest_float(\n",
        "          \"bagging_fraction\", 0.7, 0.95, step=0.01\n",
        "      ),\n",
        "      \"feature_fraction_bynode\": trial.suggest_float(\n",
        "          \"feature_fraction_bynode\", 0.7, 0.95, step=0.01\n",
        "      ),\n",
        "      \"feature_fraction\": trial.suggest_float(\n",
        "          \"bagging_fraction\", 0.8, 0.95, step=0.01\n",
        "      )\n",
        "  }\n",
        "\n",
        "  tscv = TimeSeriesSplit(n_splits=5)\n",
        "  folds = tscv.split(train_features)\n",
        "\n",
        "  dtrain = lgb.Dataset(train_features, label=train_labels)\n",
        "\n",
        "  param_grid['objective'] = \"regression\"\n",
        "  param_grid['metric'] = \"l1\"\n",
        "  param_grid['verbosity'] = -1\n",
        "  param_grid['boosting_type'] = \"gbdt\"\n",
        "\n",
        "  lgbcv = lgb.cv(param_grid,\n",
        "                 dtrain,\n",
        "                 folds=folds,\n",
        "                 shuffle=False)\n",
        "  cv_score = lgbcv['valid l1-mean'][-1] + lgbcv['valid l1-stdv'][-1]\n",
        "\n",
        "  return cv_score"
      ],
      "metadata": {
        "id": "mpVLtlSP0eoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "HA6YDF0t028v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## SJ model\n",
        "study = optuna.create_study(\n",
        "        direction=\"minimize\",\n",
        "        study_name = \"LightGBM Regression for sj\"\n",
        "    )\n",
        "func = lambda trial: lgb_objective_ts_cv(trial, sj_train_features, sj_train_labels)\n",
        "study.optimize(func, n_trials = 100)\n",
        "parameters = study.best_params\n",
        "\n",
        "reg_sj = lgb.LGBMRegressor(**parameters,\n",
        "                        random_state = 42)\n",
        "reg_sj.fit(sj_train_features, sj_train_labels, eval_metric = mean_absolute_error)\n",
        "Y_pred = reg_sj.predict(sj_validation_features).astype(int).clip(0)\n",
        "\n",
        "print(\"\\n\\nFinal MAE for validation set is {}\".format(mean_absolute_error(sj_validation_labels, Y_pred)))"
      ],
      "metadata": {
        "id": "vD-o_vwy0ZHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## IQ model\n",
        "study = optuna.create_study(\n",
        "        direction=\"minimize\",\n",
        "        study_name = \"LightGBM Regression for iq\"\n",
        "    )\n",
        "func = lambda trial: lgb_objective_ts_cv(trial, iq_train_features, iq_train_labels)\n",
        "study.optimize(func, n_trials = 100)\n",
        "parameters = study.best_params\n",
        "\n",
        "reg_iq = lgb.LGBMRegressor(**parameters,\n",
        "                        random_state = 42)\n",
        "reg_iq.fit(iq_train_features, iq_train_labels, eval_metric = mean_absolute_error)\n",
        "Y_pred = reg_iq.predict(iq_validation_features).astype(int).clip(0)\n",
        "\n",
        "print(\"\\n\\nFinal MAE for validation set is {}\".format(mean_absolute_error(iq_validation_labels, Y_pred)))"
      ],
      "metadata": {
        "id": "FfaflKTu0i2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Feature Importance Analysis"
      ],
      "metadata": {
        "id": "0BlJfwi-06Of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# explain the model's predictions using SHAP\n",
        "explainer = shap.Explainer(reg_sj)\n",
        "shap_values = explainer(sj_train_features)\n",
        "\n",
        "# summarize the effects of all the features\n",
        "shap.plots.beeswarm(shap_values)"
      ],
      "metadata": {
        "id": "Acur3bAG0wvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SHAP importance for LightGBM\n",
        "shap.plots.bar(shap_values)"
      ],
      "metadata": {
        "id": "4wMAoH140wy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# explain the model's predictions using SHAP\n",
        "explainer = shap.Explainer(reg_iq)\n",
        "shap_values = explainer(iq_train_features)\n",
        "\n",
        "# summarize the effects of all the features\n",
        "shap.plots.beeswarm(shap_values)"
      ],
      "metadata": {
        "id": "3D1V5MzL1Bva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SHAP importance for LightGBM\n",
        "shap.plots.bar(shap_values)"
      ],
      "metadata": {
        "id": "tnL8-d6n1Bxg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}